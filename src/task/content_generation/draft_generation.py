"""
Draft Generation Component for AI-driven content generation.

This component takes the structural plan and background research to generate
the final content draft.
"""

import asyncio
from typing import Optional

from pydantic import Field

from src import log
from src.core import DataCore
from src.lib.model.txt import LmBasis
from src.lib.model.txt.lm_gentxt_params import LmGentxtParams
from src.lib.model.txt.lm_gentxt_result import LmGentxtResult

from .background_discovery import BackgroundDiscoveryResult
from .prompts import DRAFT_GENERATION_PROMPT_TEMPLATE, DRAFT_GENERATION_SYSTEM_PROMPT
from .structural_planning import StructuralPlanningResult


class DraftGenerationParams(DataCore):
    """Parameters for draft generation."""

    background_research: str = Field(
        description="Comprehensive background research from the discovery phase"
    )

    structural_plan: str = Field(
        description="Detailed structural plan and content strategy"
    )

    additional_instructions: str = Field(
        default="Generate high-quality, engaging content that follows best practices for readability and engagement.",
        description="Additional specific instructions for content generation",
    )

    max_tokens: Optional[int] = Field(
        default=5000, description="Maximum tokens for the LLM response"
    )

    temperature: float = Field(
        default=0.6,
        description="Temperature for LLM generation (balanced for creative but coherent content)",
    )


class DraftGenerationResult(DataCore):
    """Result from draft generation."""

    background_research: str = Field(
        description="The background research used for generation"
    )

    structural_plan: str = Field(description="The structural plan used for generation")

    additional_instructions: str = Field(
        description="The additional instructions provided"
    )

    content_draft: str = Field(description="The generated content draft")

    input_tokens: int = Field(description="Number of input tokens used by the LLM")

    output_tokens: int = Field(
        description="Number of output tokens generated by the LLM"
    )


class DraftGeneration:
    """
    Draft Generation Component.

    Takes the structural plan and background research to generate the final
    content draft, completing the content generation pipeline.
    """

    def __init__(self, model: LmBasis, log_name: str = "draft_generation"):
        """
        Initialize the draft generation component.

        Args:
            model: Language model to use for draft generation
            log_name: Name for logging purposes
        """
        self.model = model
        self.logger = log.bind(component=log_name)

    def generate(self, params: DraftGenerationParams) -> DraftGenerationResult:
        """
        Generate a synchronous content draft.

        Args:
            params: Parameters for draft generation

        Returns:
            DraftGenerationResult containing the final content draft
        """
        self.logger.info("Starting draft generation")

        # Prepare the prompt
        prompt = DRAFT_GENERATION_PROMPT_TEMPLATE.format(
            background_research=params.background_research,
            structural_plan=params.structural_plan,
            additional_instructions=params.additional_instructions,
        )

        # Create LLM parameters
        llm_params = LmGentxtParams(
            system_prompt=DRAFT_GENERATION_SYSTEM_PROMPT,
            prompt=prompt,
            max_new_tokens=params.max_tokens,
            temperature=params.temperature,
        )

        # Call the LLM
        llm_result: LmGentxtResult = self.model.gentxt(llm_params)

        # Create and return result
        result = DraftGenerationResult(
            background_research=params.background_research,
            structural_plan=params.structural_plan,
            additional_instructions=params.additional_instructions,
            content_draft=llm_result.output,
            input_tokens=llm_result.input_tokens,
            output_tokens=llm_result.output_tokens,
        )

        self.logger.success("Draft generation completed")
        self.logger.info(f"Generated {result.output_tokens} tokens of content draft")

        return result

    async def agenerate(self, params: DraftGenerationParams) -> DraftGenerationResult:
        """
        Generate an asynchronous content draft.

        Args:
            params: Parameters for draft generation

        Returns:
            DraftGenerationResult containing the final content draft
        """
        self.logger.info("Starting async draft generation")

        # Prepare the prompt
        prompt = DRAFT_GENERATION_PROMPT_TEMPLATE.format(
            background_research=params.background_research,
            structural_plan=params.structural_plan,
            additional_instructions=params.additional_instructions,
        )

        # Create LLM parameters
        llm_params = LmGentxtParams(
            system_prompt=DRAFT_GENERATION_SYSTEM_PROMPT,
            prompt=prompt,
            max_new_tokens=params.max_tokens,
            temperature=params.temperature,
        )

        # Call the LLM asynchronously
        llm_result: LmGentxtResult = await self.model.agentxt(llm_params)

        # Create and return result
        result = DraftGenerationResult(
            background_research=params.background_research,
            structural_plan=params.structural_plan,
            additional_instructions=params.additional_instructions,
            content_draft=llm_result.output,
            input_tokens=llm_result.input_tokens,
            output_tokens=llm_result.output_tokens,
        )

        self.logger.success("Async draft generation completed")
        self.logger.info(f"Generated {result.output_tokens} tokens of content draft")

        return result

    def generate_from_planning(
        self,
        planning_result: StructuralPlanningResult,
        additional_instructions: str = "Generate high-quality, engaging content that follows best practices for readability and engagement.",
        max_tokens: Optional[int] = 5000,
        temperature: float = 0.6,
    ) -> DraftGenerationResult:
        """
        Generate a content draft directly from structural planning results.

        Args:
            planning_result: Result from structural planning component
            additional_instructions: Additional specific instructions
            max_tokens: Maximum tokens for response
            temperature: LLM temperature

        Returns:
            DraftGenerationResult containing the final content draft
        """
        params = DraftGenerationParams(
            background_research=planning_result.background_research,
            structural_plan=planning_result.structural_plan,
            additional_instructions=additional_instructions,
            max_tokens=max_tokens,
            temperature=temperature,
        )

        return self.generate(params)

    async def agenerate_from_planning(
        self,
        planning_result: StructuralPlanningResult,
        additional_instructions: str = "Generate high-quality, engaging content that follows best practices for readability and engagement.",
        max_tokens: Optional[int] = 5000,
        temperature: float = 0.6,
    ) -> DraftGenerationResult:
        """
        Generate an asynchronous content draft directly from structural planning results.

        Args:
            planning_result: Result from structural planning component
            additional_instructions: Additional specific instructions
            max_tokens: Maximum tokens for response
            temperature: LLM temperature

        Returns:
            DraftGenerationResult containing the final content draft
        """
        params = DraftGenerationParams(
            background_research=planning_result.background_research,
            structural_plan=planning_result.structural_plan,
            additional_instructions=additional_instructions,
            max_tokens=max_tokens,
            temperature=temperature,
        )

        return await self.agenerate(params)

    def generate_from_discovery_and_planning(
        self,
        discovery_result: BackgroundDiscoveryResult,
        planning_result: StructuralPlanningResult,
        additional_instructions: str = "Generate high-quality, engaging content that follows best practices for readability and engagement.",
        max_tokens: Optional[int] = 5000,
        temperature: float = 0.6,
    ) -> DraftGenerationResult:
        """
        Generate a content draft from both discovery and planning results.

        Args:
            discovery_result: Result from background discovery component
            planning_result: Result from structural planning component
            additional_instructions: Additional specific instructions
            max_tokens: Maximum tokens for response
            temperature: LLM temperature

        Returns:
            DraftGenerationResult containing the final content draft
        """
        params = DraftGenerationParams(
            background_research=discovery_result.background_research,
            structural_plan=planning_result.structural_plan,
            additional_instructions=additional_instructions,
            max_tokens=max_tokens,
            temperature=temperature,
        )

        return self.generate(params)

    async def agenerate_from_discovery_and_planning(
        self,
        discovery_result: BackgroundDiscoveryResult,
        planning_result: StructuralPlanningResult,
        additional_instructions: str = "Generate high-quality, engaging content that follows best practices for readability and engagement.",
        max_tokens: Optional[int] = 5000,
        temperature: float = 0.6,
    ) -> DraftGenerationResult:
        """
        Generate an asynchronous content draft from both discovery and planning results.

        Args:
            discovery_result: Result from background discovery component
            planning_result: Result from structural planning component
            additional_instructions: Additional specific instructions
            max_tokens: Maximum tokens for response
            temperature: LLM temperature

        Returns:
            DraftGenerationResult containing the final content draft
        """
        params = DraftGenerationParams(
            background_research=discovery_result.background_research,
            structural_plan=planning_result.structural_plan,
            additional_instructions=additional_instructions,
            max_tokens=max_tokens,
            temperature=temperature,
        )

        return await self.agenerate(params)
